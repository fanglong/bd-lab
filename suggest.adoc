== 大数据实施建议

预研学习阶段先投入一到两名员工了解大数据的概念、基本环境配置的及使用，使用HDP搭建不少于3个节点的实验集群，导入部分生产数据做一些业务场景练习，
在有实际业务输入时根据情况选择合适的技术、搭建测试生产集群，组建独立大数据团队。

=== 集群环境

一般而言需要3个独立的集群

|===
|名称 | 说明

|开发调试集群 | 用于平时的开发、调试及新技术测试等，此集群建议在5-8个节点
|测试集群 | 用于上线前的功能测试，由于测试集群使用频度及负载不高，所以5个节点比较合适
|生产集群 | 用于生产作业，至少8个节点以上
|===

=== 大数据团队

一般建议在3-12人左右，应用开发：系统运维：ETL的人员比可为 5:1:4

**以上的节点数量及人员配置仅针对初创阶段，数据量及作业量不是很大的情况，否则要具体情况具体分析。**

=== 技术选型

==== 数据采集

* 如果有很多历史在关系型数据库中且希望将这些数据导入大数据平台，那么可考虑使用`Sqoop`实现数据抽取，`Kettle`并不是为大数据而生，扩展性不好，如数据量不是很大可以尝试使用
* 如果有大量的Web数据那推荐使用`Nutch`方便地抓取网页内容
* 对于日志的分析推荐使用`Kafka`来实现，大概流程是用`Logstash`对接各类日志文件（e.g. log4j logback）
然后使用`Logstash`的`Kafka`插件将收到的日志添加到队列中，此方案可参见 http://my.oschina.net/gudaoxuri/blog/534710 

==== 数据处理

**如没有特殊情况推荐使用`Spark`作为处理引擎** 

* 如果业务需要实时处理则可使用`Spark Streaming`
* 如果需要有复杂的关系链处理可考虑使用`Spark GraphX`，用图来实现
* 如果需要做机器学习相关，如推荐引擎，则可考虑使用`Spark MLib`与`Mahout（目前版本处理引擎也是用Spark）`

==== 数据存储

* 对于需要快存快取且不需要做OLTP的业务`HBase`是比较合适的数据库
* 如果业务需要比较复杂的分析但对实时性要求不高且查询的多为历史数据（不会变更）那么`Hive`是不二之选，可以对接`Tez`或`Spark`作为处理引擎以加快处理速度
* 如果仅仅是想做留档或备份，偶尔做一些离线分析，那么直接放到`HDFS`是不错的选择
* 如果数据体量很大且业务要求做近实时的复杂分析，可考虑使用`ElasticSearch`，另外也可以关注`Drill`
* 如果数据体量__不__是很大需要做近实时复杂分析那么`Mongo`也许是一个不错的选择
* 如果只是简单的做指标统计，`Redis`是个好东西

==== 数据可视化

* 简单的图表分析可使用`Zeppelin`
* 需要平台级的工具那么推荐使用`Hue`，要效果“酷炫”可以关注`caravel`(https://github.com/airbnb/caravel)
* 如果需要做Cube分析，那么`Kylin`是首选
* 当然最贴近业务的必定是自主开发，可使用`Echarts`及`D3.js`实现定制化的图表


=== 请对以下技术保持关注

* Flink:自诩比Spark更先进的计算引擎 http://flink.apache.org/
* Phoenix: All Of SQL https://phoenix.apache.org/
* Drill:Google dremel的山寨品 http://drill.apache.org/
* Nifi 很复杂但很全面的数据分发工具，来自NSA http://nifi.apache.org/
* KyLin 很有前途的多维分析工具 http://kylin.apache.org/




